{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EcoInnovators Round 2 - YOLOv12m-seg Solar Panel Segmentation Training\n",
    "\n",
    "**Objective**: Train a state-of-the-art instance segmentation model for rooftop solar panel detection.\n",
    "\n",
    "**Model**: YOLOv12m-seg (latest, greatest)\n",
    "\n",
    "**Training Time Budget**: ~4 hours on H200\n",
    "\n",
    "**Key Improvements over Round 1**:\n",
    "1. Segmentation instead of detection (accurate area calculation)\n",
    "2. Multiple high-quality datasets merged (~10k+ images)\n",
    "3. Negative samples for false positive reduction\n",
    "4. Enhanced augmentation for robustness\n",
    "\n",
    "---\n",
    "\n",
    "## Dataset Strategy\n",
    "\n",
    "We merge multiple datasets to create a robust, diverse training set:\n",
    "\n",
    "| Priority | Dataset | Source | Images | Purpose |\n",
    "|----------|---------|--------|--------|--------|\n",
    "| **1** | Solar panels seg | Roboflow (RUT) | ~4,010 | Primary - Large scale instance segmentation |\n",
    "| **2** | NL Solar Panel Seg | Roboflow | ~4,160 | European aerial imagery diversity |\n",
    "| **3** | Solar Panels - Polygons | Roboflow | 86 | High-quality polygon annotations |\n",
    "| **4** | Solar panels RF100 | Roboflow 100 | ~1,000 | Benchmark quality |\n",
    "| **5** | Solar PV Detection | Roboflow | ~500 | Additional variety |\n",
    "| **6** | WW Solar Panel | Roboflow | ~500 | Global coverage |\n",
    "\n",
    "**Total: ~10,000+ diverse segmentation samples**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"GPU VERIFICATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    print(f\"GPU Memory: {gpu_mem:.2f} GB\")\n",
    "    \n",
    "    if gpu_mem > 70:\n",
    "        print(\"\\n‚úì H200/H100 detected - Optimal for YOLOv12m-seg training!\")\n",
    "    elif gpu_mem > 40:\n",
    "        print(\"\\n‚úì A100 detected - Great for training!\")\n",
    "else:\n",
    "    print(\"‚ö† WARNING: No GPU detected. Training will be very slow.\")\n",
    "\n",
    "print(\"\\nüì¶ Installing dependencies...\")\n",
    "!pip install -q ultralytics>=8.3.0\n",
    "!pip install -q roboflow\n",
    "!pip install -q opencv-python shapely pandas openpyxl matplotlib\n",
    "!pip install -q mlflow\n",
    "\n",
    "print(\"‚úì Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import ultralytics\n",
    "\n",
    "print(f\"Ultralytics version: {ultralytics.__version__}\")\n",
    "\n",
    "# Test YOLOv12m-seg availability\n",
    "MODEL_NAME = None\n",
    "for model_option in ['yolov12m-seg.pt', 'yolo12m-seg.pt', 'yolo11m-seg.pt']:\n",
    "    try:\n",
    "        test_model = YOLO(model_option)\n",
    "        MODEL_NAME = model_option\n",
    "        print(f\"‚úì {model_option} loaded successfully!\")\n",
    "        del test_model\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö† {model_option} not available: {str(e)[:50]}...\")\n",
    "\n",
    "if MODEL_NAME is None:\n",
    "    raise RuntimeError(\"No segmentation model available!\")\n",
    "\n",
    "print(f\"\\nüéØ Selected model: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Acquisition\n",
    "\n",
    "Download all datasets from Roboflow with instance segmentation annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import yaml\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DATASET ACQUISITION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "DATASET_ROOT = Path(\"/content/datasets\")\n",
    "DATASET_ROOT.mkdir(exist_ok=True)\n",
    "\n",
    "# Roboflow API key\n",
    "ROBOFLOW_API_KEY = \"nwjLvwd73Cvdh2afvIVD\"\n",
    "rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
    "\n",
    "# Dataset configurations - prioritized by quality and size\n",
    "datasets_config = [\n",
    "    # PRIMARY: Large instance segmentation datasets\n",
    "    {\n",
    "        \"name\": \"solar_panels_seg_rut\",\n",
    "        \"workspace\": \"rzeszow-university-of-technology-m5ydx\",\n",
    "        \"project\": \"solar-panels-seg\",\n",
    "        \"version\": 1,\n",
    "        \"format\": \"yolov8\",\n",
    "        \"priority\": 1,\n",
    "        \"description\": \"4k+ images - Rzeszow University Instance Seg\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"nl_solar_panel_seg\",\n",
    "        \"workspace\": \"rug-uofl3\",\n",
    "        \"project\": \"nl-solar-panel-seg\",\n",
    "        \"version\": 1,\n",
    "        \"format\": \"yolov8\",\n",
    "        \"priority\": 2,\n",
    "        \"description\": \"4k+ Dutch aerial imagery\"\n",
    "    },\n",
    "    # SECONDARY: High-quality smaller datasets\n",
    "    {\n",
    "        \"name\": \"solar_panels_polygons\",\n",
    "        \"workspace\": \"sophia-tierney\",\n",
    "        \"project\": \"solar-panels-polygons\",\n",
    "        \"version\": 1,\n",
    "        \"format\": \"yolov8\",\n",
    "        \"priority\": 3,\n",
    "        \"description\": \"86 high-quality polygon annotations\"\n",
    "    },\n",
    "    # TERTIARY: Original datasets (proven in Round 1)\n",
    "    {\n",
    "        \"name\": \"solar_panels_rf100\",\n",
    "        \"workspace\": \"roboflow-100\",\n",
    "        \"project\": \"solar-panels-taxvb\",\n",
    "        \"version\": 2,\n",
    "        \"format\": \"yolov8\",\n",
    "        \"priority\": 4,\n",
    "        \"description\": \"Roboflow 100 benchmark\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"solar_pv_detection\",\n",
    "        \"workspace\": \"whereareyousolarpanel\",\n",
    "        \"project\": \"solar-pv-panel-detection\",\n",
    "        \"version\": 5,\n",
    "        \"format\": \"yolov8\",\n",
    "        \"priority\": 5,\n",
    "        \"description\": \"Solar PV Panel Detection\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"ww_solar_panel\",\n",
    "        \"workspace\": \"solar-panel-2d0l1\",\n",
    "        \"project\": \"ww-solar-panel\",\n",
    "        \"version\": 16,\n",
    "        \"format\": \"yolov8\",\n",
    "        \"priority\": 6,\n",
    "        \"description\": \"WW Solar Panel global coverage\"\n",
    "    },\n",
    "]\n",
    "\n",
    "downloaded_datasets = []\n",
    "\n",
    "for ds in sorted(datasets_config, key=lambda x: x['priority']):\n",
    "    print(f\"\\nüì• [{ds['priority']}] Downloading: {ds['name']}\")\n",
    "    print(f\"   {ds['description']}\")\n",
    "    \n",
    "    try:\n",
    "        project = rf.workspace(ds['workspace']).project(ds['project'])\n",
    "        dataset = project.version(ds['version']).download(\n",
    "            ds['format'], \n",
    "            location=str(DATASET_ROOT / ds['name'])\n",
    "        )\n",
    "        downloaded_datasets.append(ds)\n",
    "        print(f\"   ‚úì Downloaded successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö† Failed: {str(e)[:80]}\")\n",
    "\n",
    "print(f\"\\n‚úì Downloaded {len(downloaded_datasets)}/{len(datasets_config)} datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset Merging & Preprocessing\n",
    "\n",
    "Merge all datasets with:\n",
    "- Unique prefixes to avoid filename collisions\n",
    "- Normalized labels (all class 0 = solar_panel)\n",
    "- Validated polygon annotations\n",
    "- Proper train/val/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"DATASET MERGING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "COMBINED_DIR = DATASET_ROOT / \"combined_solar_seg\"\n",
    "\n",
    "# Create directory structure\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    (COMBINED_DIR / split / 'images').mkdir(parents=True, exist_ok=True)\n",
    "    (COMBINED_DIR / split / 'labels').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def normalize_and_copy_dataset(source_dir, prefix, stats):\n",
    "    \"\"\"\n",
    "    Copy dataset with prefix, normalize labels to class 0.\n",
    "    Handles both detection (5 values) and segmentation (polygon) formats.\n",
    "    \"\"\"\n",
    "    source = Path(source_dir)\n",
    "    \n",
    "    for split in ['train', 'valid', 'test', 'val']:\n",
    "        img_src = source / split / 'images'\n",
    "        lbl_src = source / split / 'labels'\n",
    "        \n",
    "        if not img_src.exists():\n",
    "            continue\n",
    "        \n",
    "        # Map 'val' to 'valid'\n",
    "        target_split = 'valid' if split == 'val' else split\n",
    "        img_dst = COMBINED_DIR / target_split / 'images'\n",
    "        lbl_dst = COMBINED_DIR / target_split / 'labels'\n",
    "        \n",
    "        # Copy images\n",
    "        for img_file in img_src.glob('*'):\n",
    "            if img_file.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp', '.webp']:\n",
    "                new_name = f\"{prefix}_{img_file.name}\"\n",
    "                shutil.copy(img_file, img_dst / new_name)\n",
    "                stats['images'] += 1\n",
    "        \n",
    "        # Copy and normalize labels\n",
    "        if lbl_src.exists():\n",
    "            for lbl_file in lbl_src.glob('*.txt'):\n",
    "                new_name = f\"{prefix}_{lbl_file.name}\"\n",
    "                \n",
    "                with open(lbl_file, 'r') as f:\n",
    "                    lines = f.readlines()\n",
    "                \n",
    "                normalized_lines = []\n",
    "                for line in lines:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) >= 5:  # Valid annotation\n",
    "                        parts[0] = '0'  # Normalize to class 0\n",
    "                        normalized_lines.append(' '.join(parts))\n",
    "                        \n",
    "                        # Count polygon vs bbox\n",
    "                        if len(parts) > 5:\n",
    "                            stats['polygons'] += 1\n",
    "                        else:\n",
    "                            stats['boxes'] += 1\n",
    "                \n",
    "                if normalized_lines:\n",
    "                    with open(lbl_dst / new_name, 'w') as f:\n",
    "                        f.write('\\n'.join(normalized_lines) + '\\n')\n",
    "                    stats['labels'] += 1\n",
    "\n",
    "# Merge all datasets\n",
    "total_stats = {'images': 0, 'labels': 0, 'polygons': 0, 'boxes': 0}\n",
    "\n",
    "for ds in downloaded_datasets:\n",
    "    ds_path = DATASET_ROOT / ds['name']\n",
    "    if ds_path.exists():\n",
    "        prefix = ds['name'][:8]  # Short prefix\n",
    "        print(f\"\\nüìÅ Merging: {ds['name']}\")\n",
    "        \n",
    "        ds_stats = {'images': 0, 'labels': 0, 'polygons': 0, 'boxes': 0}\n",
    "        normalize_and_copy_dataset(ds_path, prefix, ds_stats)\n",
    "        \n",
    "        print(f\"   Images: {ds_stats['images']}\")\n",
    "        print(f\"   Labels: {ds_stats['labels']}\")\n",
    "        print(f\"   Polygons: {ds_stats['polygons']} | Boxes: {ds_stats['boxes']}\")\n",
    "        \n",
    "        for k in total_stats:\n",
    "            total_stats[k] += ds_stats[k]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMBINED DATASET STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total Images: {total_stats['images']}\")\n",
    "print(f\"Total Labels: {total_stats['labels']}\")\n",
    "print(f\"Polygon Annotations: {total_stats['polygons']}\")\n",
    "print(f\"Box Annotations: {total_stats['boxes']}\")\n",
    "print(f\"\\nSegmentation Ratio: {total_stats['polygons']/(total_stats['polygons']+total_stats['boxes']+1e-10)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data.yaml\n",
    "data_yaml = {\n",
    "    'path': str(COMBINED_DIR),\n",
    "    'train': 'train/images',\n",
    "    'val': 'valid/images',\n",
    "    'test': 'test/images',\n",
    "    'names': {\n",
    "        0: 'solar_panel'\n",
    "    },\n",
    "    'nc': 1\n",
    "}\n",
    "\n",
    "yaml_path = COMBINED_DIR / 'data.yaml'\n",
    "with open(yaml_path, 'w') as f:\n",
    "    yaml.dump(data_yaml, f, default_flow_style=False)\n",
    "\n",
    "print(f\"‚úì Created data.yaml at {yaml_path}\")\n",
    "\n",
    "# Count final splits\n",
    "print(\"\\nüìä Final Split Distribution:\")\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    img_path = COMBINED_DIR / split / 'images'\n",
    "    lbl_path = COMBINED_DIR / split / 'labels'\n",
    "    if img_path.exists():\n",
    "        img_count = len(list(img_path.glob('*')))\n",
    "        lbl_count = len(list(lbl_path.glob('*.txt')))\n",
    "        print(f\"   {split:6s}: {img_count:5d} images, {lbl_count:5d} labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Configuration\n",
    "\n",
    "Optimized for ~4 hours on H200 with maximum quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TRAINING CONFIGURATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load model\n",
    "model = YOLO(MODEL_NAME)\n",
    "print(f\"‚úì Loaded {MODEL_NAME}\")\n",
    "\n",
    "# Calculate optimal batch size\n",
    "if torch.cuda.is_available():\n",
    "    gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    \n",
    "    if gpu_mem > 70:      # H200/H100 (80GB)\n",
    "        BATCH_SIZE = 32\n",
    "    elif gpu_mem > 40:    # A100 (40/80GB)\n",
    "        BATCH_SIZE = 24\n",
    "    elif gpu_mem > 20:    # A10G/V100 (24/32GB)\n",
    "        BATCH_SIZE = 16\n",
    "    else:                 # Smaller GPUs\n",
    "        BATCH_SIZE = 8\n",
    "else:\n",
    "    BATCH_SIZE = 4\n",
    "\n",
    "print(f\"GPU Memory: {gpu_mem:.0f}GB ‚Üí Batch Size: {BATCH_SIZE}\")\n",
    "\n",
    "# Training configuration\n",
    "training_args = {\n",
    "    # ===== DATA =====\n",
    "    'data': str(yaml_path),\n",
    "    'imgsz': 640,\n",
    "    \n",
    "    # ===== TRAINING SCHEDULE =====\n",
    "    'epochs': 120,              # ~4 hours on H200 with 10k images\n",
    "    'batch': BATCH_SIZE,\n",
    "    'patience': 25,             # Early stopping\n",
    "    'close_mosaic': 15,         # Disable mosaic for last 15 epochs\n",
    "    \n",
    "    # ===== MODEL =====\n",
    "    'task': 'segment',\n",
    "    'single_cls': True,\n",
    "    'pretrained': True,\n",
    "    \n",
    "    # ===== OPTIMIZER =====\n",
    "    'optimizer': 'AdamW',\n",
    "    'lr0': 0.0005,              # Lower for stability\n",
    "    'lrf': 0.01,\n",
    "    'momentum': 0.937,\n",
    "    'weight_decay': 0.0005,\n",
    "    'warmup_epochs': 5.0,\n",
    "    'warmup_momentum': 0.8,\n",
    "    'warmup_bias_lr': 0.1,\n",
    "    \n",
    "    # ===== LOSS WEIGHTS =====\n",
    "    'box': 7.5,\n",
    "    'cls': 0.5,\n",
    "    'dfl': 1.5,\n",
    "    \n",
    "    # ===== AUGMENTATION (Enhanced) =====\n",
    "    'hsv_h': 0.015,\n",
    "    'hsv_s': 0.7,\n",
    "    'hsv_v': 0.4,\n",
    "    'degrees': 15.0,            # Rotation for varied orientations\n",
    "    'translate': 0.15,\n",
    "    'scale': 0.7,               # More scale variation\n",
    "    'shear': 5.0,               # Perspective distortion\n",
    "    'perspective': 0.0005,\n",
    "    'flipud': 0.5,              # Aerial imagery benefits from this\n",
    "    'fliplr': 0.5,\n",
    "    'mosaic': 1.0,\n",
    "    'mixup': 0.2,\n",
    "    'copy_paste': 0.3,          # Great for segmentation!\n",
    "    \n",
    "    # ===== TRAINING SETTINGS =====\n",
    "    'device': 0,\n",
    "    'workers': 8,\n",
    "    'cache': 'ram',             # Fast training\n",
    "    'amp': True,                # Mixed precision\n",
    "    'cos_lr': True,\n",
    "    'seed': 42,\n",
    "    'deterministic': True,\n",
    "    \n",
    "    # ===== SAVING =====\n",
    "    'project': '/content/runs/segment',\n",
    "    'name': 'solar_yolov12_seg',\n",
    "    'save': True,\n",
    "    'save_period': 10,\n",
    "    'exist_ok': True,\n",
    "    'verbose': True,\n",
    "    'plots': True,\n",
    "}\n",
    "\n",
    "print(\"\\nüìã Configuration Summary:\")\n",
    "print(f\"  Model: {MODEL_NAME}\")\n",
    "print(f\"  Epochs: {training_args['epochs']}\")\n",
    "print(f\"  Batch Size: {training_args['batch']}\")\n",
    "print(f\"  Image Size: {training_args['imgsz']}\")\n",
    "print(f\"  Augmentation: Mosaic + MixUp + CopyPaste\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "start_time = datetime.now()\n",
    "print(f\"\\nüöÄ Started: {start_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"‚è±Ô∏è Estimated: ~4 hours on H200\")\n",
    "print(\"\\n\" + \"-\"*80 + \"\\n\")\n",
    "\n",
    "# Train!\n",
    "results = model.train(**training_args)\n",
    "\n",
    "end_time = datetime.now()\n",
    "duration = end_time - start_time\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Finished: {end_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Duration: {duration}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"MODEL EVALUATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load best model\n",
    "best_path = Path('/content/runs/segment/solar_yolov12_seg/weights/best.pt')\n",
    "best_model = YOLO(best_path) if best_path.exists() else model\n",
    "print(f\"‚úì Loaded: {best_path if best_path.exists() else 'current model'}\")\n",
    "\n",
    "# Validate\n",
    "print(\"\\nüìä Running validation...\")\n",
    "metrics = best_model.val(data=str(yaml_path))\n",
    "\n",
    "# Extract metrics\n",
    "box_map50 = float(metrics.box.map50)\n",
    "box_map = float(metrics.box.map)\n",
    "precision = float(metrics.box.mp)\n",
    "recall = float(metrics.box.mr)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
    "\n",
    "seg_map50 = float(metrics.seg.map50) if hasattr(metrics, 'seg') else 0\n",
    "seg_map = float(metrics.seg.map) if hasattr(metrics, 'seg') else 0\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüì¶ Detection Metrics:\")\n",
    "print(f\"   mAP@50:     {box_map50:.4f}\")\n",
    "print(f\"   mAP@50-95:  {box_map:.4f}\")\n",
    "print(f\"   Precision:  {precision:.4f}\")\n",
    "print(f\"   Recall:     {recall:.4f}\")\n",
    "print(f\"   F1 Score:   {f1_score:.4f}\")\n",
    "\n",
    "print(f\"\\nüé≠ Segmentation Metrics:\")\n",
    "print(f\"   Mask mAP@50:     {seg_map50:.4f}\")\n",
    "print(f\"   Mask mAP@50-95:  {seg_map:.4f}\")\n",
    "\n",
    "# Target check\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TARGET ACHIEVEMENT\")\n",
    "print(\"=\"*80)\n",
    "targets = [\n",
    "    ('F1 >= 0.85', f1_score, 0.85),\n",
    "    ('mAP@50 >= 0.80', box_map50, 0.80),\n",
    "    ('Precision >= 0.80', precision, 0.80),\n",
    "    ('Recall >= 0.80', recall, 0.80),\n",
    "]\n",
    "\n",
    "all_passed = True\n",
    "for name, value, target in targets:\n",
    "    passed = value >= target\n",
    "    status = \"‚úì\" if passed else \"‚úó\"\n",
    "    print(f\"   {status} {name}: {value:.4f}\")\n",
    "    all_passed = all_passed and passed\n",
    "\n",
    "if all_passed:\n",
    "    print(\"\\nüéâ ALL TARGETS MET!\")\n",
    "else:\n",
    "    print(\"\\n‚ö† Some targets not met.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export Training Logs & Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TRAINING LOGS EXPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results_csv = Path('/content/runs/segment/solar_yolov12_seg/results.csv')\n",
    "\n",
    "if results_csv.exists():\n",
    "    df = pd.read_csv(results_csv)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    \n",
    "    # Save\n",
    "    df.to_csv('/content/training_logs.csv', index=False)\n",
    "    print(\"‚úì Saved: /content/training_logs.csv\")\n",
    "    \n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    \n",
    "    # Losses\n",
    "    for ax, loss_type in zip(axes[0], ['box', 'seg', 'cls']):\n",
    "        train_col = f'train/{loss_type}_loss'\n",
    "        val_col = f'val/{loss_type}_loss'\n",
    "        if train_col in df.columns:\n",
    "            ax.plot(df['epoch'], df[train_col], label='Train')\n",
    "        if val_col in df.columns:\n",
    "            ax.plot(df['epoch'], df[val_col], label='Val')\n",
    "        ax.set_title(f'{loss_type.upper()} Loss')\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "    \n",
    "    # Metrics\n",
    "    if 'metrics/precision(B)' in df.columns:\n",
    "        axes[1, 0].plot(df['epoch'], df['metrics/precision(B)'], label='Precision')\n",
    "        axes[1, 0].plot(df['epoch'], df['metrics/recall(B)'], label='Recall')\n",
    "        axes[1, 0].set_title('Precision & Recall')\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True)\n",
    "    \n",
    "    if 'metrics/mAP50(B)' in df.columns:\n",
    "        axes[1, 1].plot(df['epoch'], df['metrics/mAP50(B)'], label='mAP@50')\n",
    "        axes[1, 1].axhline(y=0.80, color='red', linestyle='--', label='Target')\n",
    "        axes[1, 1].set_title('mAP@50')\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].grid(True)\n",
    "    \n",
    "    if 'metrics/precision(B)' in df.columns:\n",
    "        f1 = 2 * (df['metrics/precision(B)'] * df['metrics/recall(B)']) / \\\n",
    "             (df['metrics/precision(B)'] + df['metrics/recall(B)'] + 1e-10)\n",
    "        axes[1, 2].plot(df['epoch'], f1, label='F1', color='green')\n",
    "        axes[1, 2].axhline(y=0.85, color='red', linestyle='--', label='Target')\n",
    "        axes[1, 2].set_title('F1 Score')\n",
    "        axes[1, 2].legend()\n",
    "        axes[1, 2].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('/content/training_curves.png', dpi=150)\n",
    "    plt.show()\n",
    "    print(\"‚úì Saved: /content/training_curves.png\")\n",
    "else:\n",
    "    print(\"‚ö† Results CSV not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Inference Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"INFERENCE DEMO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "val_images = list((COMBINED_DIR / 'valid' / 'images').glob('*'))[:6]\n",
    "\n",
    "if val_images:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for idx, img_path in enumerate(val_images):\n",
    "        results = best_model.predict(str(img_path), conf=0.25, iou=0.45)\n",
    "        \n",
    "        annotated = results[0].plot()\n",
    "        annotated = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        n = len(results[0].boxes) if results[0].boxes is not None else 0\n",
    "        \n",
    "        axes[idx].imshow(annotated)\n",
    "        axes[idx].set_title(f\"Detected: {n} panels\")\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('/content/inference_samples.png', dpi=150)\n",
    "    plt.show()\n",
    "    print(\"‚úì Saved: /content/inference_samples.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export for Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PRODUCTION EXPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "export_dir = Path('/content/exports')\n",
    "export_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Copy best model\n",
    "best_weights = Path('/content/runs/segment/solar_yolov12_seg/weights/best.pt')\n",
    "if best_weights.exists():\n",
    "    export_path = export_dir / 'yolov12_seg_solar_panel.pt'\n",
    "    shutil.copy(best_weights, export_path)\n",
    "    size_mb = export_path.stat().st_size / 1024**2\n",
    "    print(f\"‚úì Model: {export_path.name} ({size_mb:.1f} MB)\")\n",
    "\n",
    "# Copy artifacts\n",
    "for src, dst in [\n",
    "    ('/content/training_logs.csv', 'training_logs.csv'),\n",
    "    ('/content/training_curves.png', 'training_curves.png'),\n",
    "    ('/content/inference_samples.png', 'inference_samples.png'),\n",
    "]:\n",
    "    if Path(src).exists():\n",
    "        shutil.copy(src, export_dir / dst)\n",
    "        print(f\"‚úì Copied: {dst}\")\n",
    "\n",
    "print(f\"\\nüìÅ Export directory: {export_dir}\")\n",
    "print(\"\\nüìã Files to download:\")\n",
    "for f in export_dir.iterdir():\n",
    "    print(f\"   - {f.name}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"NEXT STEPS\")\n",
    "print(\"=\"*80)\n",
    "print(\"1. Download yolov12_seg_solar_panel.pt\")\n",
    "print(\"2. Replace model/best.pt in your repository\")\n",
    "print(\"3. Update src/config.py with MODEL_FILENAME\")\n",
    "print(\"4. Update src/detector.py to model_type='yolo11' or 'yolo12'\")\n",
    "print(\"5. Run the pipeline!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
